# 内存映射

就我们所知，C标准库提供了mmap函数建立映射。在内核一端，提供了两个系统调用`sys_mmap`和`sys_mmap2`。
```c
asmlinkage unsigned long sys_mmap{2}(unsigned long addr, 
                unsigned long len,
                unsigned long prot, 
                unsigned long flags,
                unsigned long fd, 
                unsigned long off)
static inline unsigned long do_mmap(struct file *file, 
                unsigned long addr, 
                unsigned long len, 
                unsigned long prot, 
                unsigned long flag, 
                unsigned long offset)
unsigned long do_mmap_pgoff(struct file *file,
			    unsigned long addr,
			    unsigned long len,
			    unsigned long prot,
			    unsigned long flags,
			    unsigned long pgoff)
```
- 这两个调用都会在用户虚拟地址空间中的pos位置，建立一个长度为len的映射，其访问权限通过prot定义。flags是一个标志集，用于设置一些参数。相关的文件通过其文件描述符fd标识
- mmap和mmap2之间的差别在于偏移量的语义（off）。在这两个调用中，它都表示映射在文件中开始的位置。对于mmap，位置的单位是字节，而mmap2使用的单位则是页（PAGE_SIZE）。因此即使文件比可用地址空间大，也可以映射文件的一部分。
- 可使用munmap系统调用删除映射。因为不需要文件偏移量，因此不需要munmap2系统调用，只需提供映射的虚拟地址

## 创建映射

这里简要地列出`mmap`可以设置的最重要的`flag`。
- MAP_FIXED: 指定除了给定地址之外，不能将其他地址用于映射。如果没有设置该标志，内核可以在受阻时随意改变目标地址。例如，在目标地址已经存在一个映射的情况（否则，现存的映射将被覆盖）。
- MAP_SHARED: 如果一个对象（通常是文件）在几个进程之间共享时，则必须使用MAP_SHARED。
- MAP_PRIVATE: 创建一个与数据源分离的私有映射，对映射区域的写入操作不影响文件中的数据。
- MAP_ANONYMOUS: 创建与任何数据源都不相关的匿名映射，fd和off参数被忽略。此类映射可用于为应用程序分配类似malloc所用的内存。

prot可指定PROT_EXEC、PROT_READ、PROT_WRITE、PROT_NONE值的组合，来定义访问权限。并非所有处理器都实现了所有组合，因而区域实际授予的权限可能比指定的要多。尽管内核尽力设置指定的权限，但它只能保证实际设置的访问权限不会比指定的权限有更多的限制

为简明起见，下文只讨论`sys_mmap2`（`sys_mmap`在大多数其他体系结构上的行为是类似的：最终都会到达下文讨论的`do_mmap_pgoff`函数）。该函数用作mmap2系统调用的入口，其实现立即将工作委托给`do_mmap2`。内核在其中提供文件描述符找到`file`实例，以及所处理文件的所有特征数据（第8章将更仔细地讲述该数据结构）。剩余的工作委托给`do_mmap_pgoff`。

do_mmap_pgoff是一个体系结构无关的函数，定义在mm/mmap.c。
```c
static inline unsigned long do_mmap(struct file *file, unsigned long addr,
	unsigned long len, unsigned long prot,
	unsigned long flag, unsigned long offset)
{
	unsigned long ret = -EINVAL;
	if ((offset + PAGE_ALIGN(len)) < offset)
		goto out;
	if (!(offset & ~PAGE_MASK))
		ret = do_mmap_pgoff(file, addr, len, prot, flag, offset >> PAGE_SHIFT);
out:
	return ret;
}

unsigned long do_mmap_pgoff(struct file * file, unsigned long addr,
			unsigned long len, unsigned long prot,
			unsigned long flags, unsigned long pgoff)
{
	struct mm_struct * mm = current->mm;
	struct inode *inode;
	unsigned int vm_flags;
	int error;
	int accountable = 1;
	unsigned long reqprot = prot;

	if ((prot & PROT_READ) && (current->personality & READ_IMPLIES_EXEC))
		if (!(file && (file->f_path.mnt->mnt_flags & MNT_NOEXEC)))
			prot |= PROT_EXEC;

	if (!len)
		return -EINVAL;

	if (!(flags & MAP_FIXED))
		addr = round_hint_to_min(addr);

	error = arch_mmap_check(addr, len, flags);
	if (error)
		return error;

	len = PAGE_ALIGN(len);
	if (!len || len > TASK_SIZE)
		return -ENOMEM;

	if ((pgoff + (len >> PAGE_SHIFT)) < pgoff)
               return -EOVERFLOW;

	if (mm->map_count > sysctl_max_map_count)
		return -ENOMEM;

	addr = get_unmapped_area(file, addr, len, pgoff, flags);
	if (addr & ~PAGE_MASK)
		return addr;

	vm_flags = calc_vm_prot_bits(prot) | calc_vm_flag_bits(flags) |
			mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;

	if (flags & MAP_LOCKED) {
		if (!can_do_mlock())
			return -EPERM;
		vm_flags |= VM_LOCKED;
	}
	
	if (vm_flags & VM_LOCKED) {
		unsigned long locked, lock_limit;
		locked = len >> PAGE_SHIFT;
		locked += mm->locked_vm;
		lock_limit = current->signal->rlim[RLIMIT_MEMLOCK].rlim_cur;
		lock_limit >>= PAGE_SHIFT;
		if (locked > lock_limit && !capable(CAP_IPC_LOCK))
			return -EAGAIN;
	}

	inode = file ? file->f_path.dentry->d_inode : NULL;

	error = security_file_mmap(file, reqprot, prot, flags, addr, 0);
	if (error)
		return error;

	return mmap_region(file, addr, len, flags, vm_flags, pgoff,
			   accountable);
}

unsigned long mmap_region(struct file *file, unsigned long addr,
			  unsigned long len, unsigned long flags,
			  unsigned int vm_flags, unsigned long pgoff,
			  int accountable)
{
	struct mm_struct *mm = current->mm;
	struct vm_area_struct *vma, *prev;
	int correct_wcount = 0;
	int error;
	struct rb_node **rb_link, *rb_parent;
	unsigned long charged = 0;
	struct inode *inode =  file ? file->f_path.dentry->d_inode : NULL;

	/* Clear old maps */
	error = -ENOMEM;
munmap_back:
	vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
	if (vma && vma->vm_start < addr + len) {
		if (do_munmap(mm, addr, len))
			return -ENOMEM;
		goto munmap_back;
	}
	if (!may_expand_vm(mm, len >> PAGE_SHIFT))
		return -ENOMEM;

	if (accountable && (!(flags & MAP_NORESERVE) ||
			    sysctl_overcommit_memory == OVERCOMMIT_NEVER)) {
		if (vm_flags & VM_SHARED) {
			/* Check memory availability in shmem_file_setup? */
			vm_flags |= VM_ACCOUNT;
		} else if (vm_flags & VM_WRITE) {
			/*
			 * Private writable mapping: check memory availability
			 */
			charged = len >> PAGE_SHIFT;
			if (security_vm_enough_memory(charged))
				return -ENOMEM;
			vm_flags |= VM_ACCOUNT;
		}
	}

	if (!file && !(vm_flags & VM_SHARED) &&
	    vma_merge(mm, prev, addr, addr + len, vm_flags,
					NULL, NULL, pgoff, NULL))
		goto out;

	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
	if (!vma) {
		error = -ENOMEM;
		goto unacct_error;
	}

	vma->vm_mm = mm;
	vma->vm_start = addr;
	vma->vm_end = addr + len;
	vma->vm_flags = vm_flags;
	vma->vm_page_prot = vm_get_page_prot(vm_flags);
	vma->vm_pgoff = pgoff;

	if (file) {
		error = -EINVAL;
		if (vm_flags & (VM_GROWSDOWN|VM_GROWSUP))
			goto free_vma;
		if (vm_flags & VM_DENYWRITE) {
			error = deny_write_access(file);
			if (error)
				goto free_vma;
			correct_wcount = 1;
		}
		vma->vm_file = file;
		get_file(file);
		error = file->f_op->mmap(file, vma);
		if (error)
			goto unmap_and_free_vma;
	} else if (vm_flags & VM_SHARED) {
		error = shmem_zero_setup(vma);
		if (error)
			goto free_vma;
	}


	if ((vm_flags & (VM_SHARED|VM_ACCOUNT)) == (VM_SHARED|VM_ACCOUNT))
		vma->vm_flags &= ~VM_ACCOUNT;

	addr = vma->vm_start;
	pgoff = vma->vm_pgoff;
	vm_flags = vma->vm_flags;

	if (vma_wants_writenotify(vma))
		vma->vm_page_prot = vm_get_page_prot(vm_flags & ~VM_SHARED);

	if (!file || !vma_merge(mm, prev, addr, vma->vm_end,
			vma->vm_flags, NULL, file, pgoff, vma_policy(vma))) {
		file = vma->vm_file;
		vma_link(mm, vma, prev, rb_link, rb_parent);
		if (correct_wcount)
			atomic_inc(&inode->i_writecount);
	} else {
		if (file) {
			if (correct_wcount)
				atomic_inc(&inode->i_writecount);
			fput(file);
		}
		mpol_free(vma_policy(vma));
		kmem_cache_free(vm_area_cachep, vma);
	}
out:	
	mm->total_vm += len >> PAGE_SHIFT;
	vm_stat_account(mm, vm_flags, file, len >> PAGE_SHIFT);
	if (vm_flags & VM_LOCKED) {
		mm->locked_vm += len >> PAGE_SHIFT;
		make_pages_present(addr, addr + len);
	}
	if ((flags & MAP_POPULATE) && !(flags & MAP_NONBLOCK))
		make_pages_present(addr, addr + len);
	return addr;

unmap_and_free_vma:
	if (correct_wcount)
		atomic_inc(&inode->i_writecount);
	vma->vm_file = NULL;
	fput(file);

	/* Undo any partial mapping done by a device driver. */
	unmap_region(mm, vma, prev, vma->vm_start, vma->vm_end);
	charged = 0;
free_vma:
	kmem_cache_free(vm_area_cachep, vma);
unacct_error:
	if (charged)
		vm_unacct_memory(charged);
	return error;
}

```
1. 调用get_unmapped_area()获得新线性区的线性地址区间
2. 将prot和flags参数中的值组合计算新的标志，接下来交给`mmap_region`函数
3. 调用`find_vam_prepare`确定新区间之前的线性对象位置，以及在红黑树中的位置
4. 如果在指定的映射位置已经存在一个映射，则通过`do_munmap`删除它
5. 如果新的区间时私有的没有设置(VM_SHARED)，且映射的不是磁盘上的文件，那么调用`vma_merge`尝试合并区间
6. 调用slab的分配函数分配`struct vm_area_struct`数据结构,并初始化
7. 调用vma_link()把新线性区插入到线性区和红黑树中
8. 增加total_vm字段的值

## 删除映射
从虚拟地址空间删除现存映射，必须使用`munmap`系统调用，它需要两个参数：解除映射区域的起始地址和长度。`sys_munmap`是该系统调用的入口。它按惯例将其工作委托给定义在`mm_mmap.c`中的`do_munmap`函数

尝试分离合并的区域 然后解除并删除节点
```c
int do_munmap(struct mm_struct *mm, unsigned long start, size_t len)
{
	unsigned long end;
	struct vm_area_struct *vma, *prev, *last;

	if ((start & ~PAGE_MASK) || start > TASK_SIZE || len > TASK_SIZE-start)
		return -EINVAL;

	if ((len = PAGE_ALIGN(len)) == 0)
		return -EINVAL;

	// 寻找到前一个节点
	vma = find_vma_prev(mm, start, &prev);
	if (!vma)
		return 0;

	end = start + len;
	if (vma->vm_start >= end)
		return 0;


    // 如果当前地址与查询到的区域的首地址不同，则需要分离区域
	if (start > vma->vm_start) {
		int error = split_vma(mm, vma, start, 0);
		if (error)
			return error;
		prev = vma;
	}

	last = find_vma(mm, end);
	if (last && end > last->vm_start) {
		int error = split_vma(mm, last, end, 1);
		if (error)
			return error;
	}
	vma = prev? prev->vm_next: mm->mmap;

    // 列出从开始到end的所有的区域
	detach_vmas_to_be_unmapped(mm, vma, prev, end);

    // 解除映射
	unmap_region(mm, vma, prev, start, end);

    // 删除节点
	remove_vma_list(mm, vma);

	return 0;
}
```
内核首先必须调用find_vma_prev，以找到解除映射区域的vm_area_struct实例。该函数的操作方式与之前讨论的find_vma完全相同，但它不仅会找到与地址匹配的vm_area_struct实例，还会返回指向前一个区域的指针。
如果解除映射区域的起始地址与find_vma_prev找到的区域起始地址不同，则只解除部分映射，而不是整个映射区域。在内核这样做之前，首先必须将现存的映射划分为几个部分。映射的前一部分不需要解除映射，首先通过split_vma分裂出来。这是一个辅助函数，我不会讨论其内容，因为其中都是对熟悉的数据结构进行标准操作。它只是分配一个新的vm_area_struct实例，用原区域的数据填充它，并校准边界。新的区域插入到进程的数据结构中。